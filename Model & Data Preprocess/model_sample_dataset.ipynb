{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops \n",
    "\n",
    "from collections import Counter \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><i>Dataset Preprocessing</i></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir path for sample dataset\n",
    "dir_path = os.getcwd() \n",
    "genuine_path = dir_path + '\\\\sample dataset\\\\sample_Signature\\\\genuine\\\\'\n",
    "forged_path = dir_path + '\\\\sample dataset\\\\sample_Signature\\\\forged\\\\'\n",
    "forged_class_path = dir_path + '\\\\sample dataset\\\\sample_Signature\\\\forged_classification\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "x_true = []\n",
    "x_false = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFI-00101001.png\n",
      "NFI-00102001.png\n",
      "NFI-00103001.png\n",
      "NFI-00104001.png\n",
      "NFI-00105001.png\n",
      "NFI-00201002.png\n",
      "NFI-00301001.png\n",
      "NFI-00302001.png\n",
      "NFI-00303001.png\n",
      "NFI-00304001.png\n",
      "NFI-00305001.png\n"
     ]
    }
   ],
   "source": [
    "for folderName, subfolders, filenames in os.walk(genuine_path):\n",
    "    for filename in filenames:\n",
    "        print(filename)\n",
    "        if(filename[9:12] == '001'):\n",
    "            temp_img = image.load_img(genuine_path+filename,target_size=(224,224))\n",
    "            temp_img = image.img_to_array(temp_img)\n",
    "            X.append(temp_img)\n",
    "            x_true.append(temp_img)\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            break\n",
    "for folderName,subfolders,filenames in os.walk(forged_class_path+'NFI-XXXYY001\\\\'):\n",
    "    for filename in filenames:\n",
    "        print(filename)\n",
    "        temp_img = image.load_img(forged_class_path+'NFI-XXXYY001\\\\'+filename,target_size=(224,224))\n",
    "        temp_img = image.img_to_array(temp_img)\n",
    "        X.append(temp_img)\n",
    "        x_false.append(temp_img)\n",
    "        Y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true = np.array(x_true)\n",
    "x_false = np.array(x_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 224, 224, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_false.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen_true = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        horizontal_flip=False,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "datagen_false = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        horizontal_flip=False,\n",
    "        fill_mode='nearest')\n",
    "datagen_true.fit(x_true)\n",
    "datagen_false.fit(x_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 224, 224, 3)\n",
      "(5, 224, 224, 3)\n",
      "(5, 224, 224, 3)\n",
      "(5, 224, 224, 3)\n",
      "(5, 224, 224, 3)\n",
      "(5, 224, 224, 3)\n",
      "(5, 224, 224, 3)\n",
      "(5, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for batch in datagen_true.flow(x_true, y=None):\n",
    "    i = i + 1\n",
    "    if i >= 9:\n",
    "        break\n",
    "    print(batch.shape)\n",
    "    for img in batch:\n",
    "        X.append(img)\n",
    "        Y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in datagen_true.flow(x_false, y=None, batch_size=32):\n",
    "    i = i + 1\n",
    "    if i >= 9:\n",
    "        break\n",
    "    for img in batch:\n",
    "        X.append(img)\n",
    "        Y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 224, 224, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ae1bc00f60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, x, train_y, y = train_test_split(X, Y, test_size = 0.2, random_state = 1)\n",
    "test_x, val_x, test_y, val_y = train_test_split(x, y, test_size = 0.5, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 224, 224, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <i> Model Structure </i> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16 model \n",
    "model_vgg = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = model_vgg.predict(train_x)\n",
    "features_val = model_vgg.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 7, 7, 512)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_x = features_train.reshape(72,25088)\n",
    "Val_x = features_val.reshape(9,25088)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting model \n",
    "model.add(Dense(1000,input_dim=25088,activation='relu',kernel_initializer='uniform'))\n",
    "model.add(Dense(100,input_dim=1000,activation='relu',kernel_initializer='uniform'))\n",
    "model.add(Dense(10,input_dim=100,activation='relu',kernel_initializer='uniform'))\n",
    "model.add(Dense(units=2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='mean_squared_error',optimizer=\"adam\",metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1000)              25089000  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 25,190,132\n",
      "Trainable params: 25,190,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "Train_Y = to_categorical(train_y,num_classes=2)\n",
    "Val_Y = to_categorical(val_y,num_classes=2)\n",
    "Test_Y = to_categorical(test_y,num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72 samples, validate on 9 samples\n",
      "Epoch 1/10\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.1562 - acc: 0.8056 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 6.7340e-06 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 5.1723e-05 - acc: 1.0000 - val_loss: 7.4170e-05 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 7.7553e-05 - acc: 1.0000 - val_loss: 3.7308e-05 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 4.1071e-05 - acc: 1.0000 - val_loss: 1.5958e-05 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0875e-05 - acc: 1.0000 - val_loss: 6.9313e-06 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.7602e-06 - acc: 1.0000 - val_loss: 2.1545e-06 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.4574e-06 - acc: 1.0000 - val_loss: 8.8339e-07 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 6.0209e-07 - acc: 1.0000 - val_loss: 4.7750e-07 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.7580e-07 - acc: 1.0000 - val_loss: 3.1429e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae1e9b5898>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Train_x, Train_Y, epochs=10,batch_size=16,validation_data=(Val_x,Val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 224, 224, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = model_vgg.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 7, 7, 512)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_X = features_test.reshape(9,25088)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 25088)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_class = model.predict(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.999999e-01, 7.016018e-06], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Y[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
