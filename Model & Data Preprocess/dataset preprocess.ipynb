{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops \n",
    "\n",
    "from collections import Counter \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adilf\\Deeplearning Projects\\hackerearth#5\\Dataset\\\n"
     ]
    }
   ],
   "source": [
    "# dir path for sample dataset\n",
    "dir_path = os.getcwd() \n",
    "dataset_path = dir_path + '\\\\Dataset\\\\'\n",
    "dataset2_path = dir_path + '\\\\Dataset2\\\\'\n",
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "x_true = []\n",
    "x_false = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset1\n",
    "\n",
    "for folderName, subfolders, filenames in os.walk(dataset_path):\n",
    "    for subfolder in subfolders:\n",
    "        for _,sF,_ in os.walk(dataset_path+subfolder):\n",
    "            if(len(sF) != 0):\n",
    "                for _,_,im in os.walk(dataset_path+subfolder+'\\\\'+sF[0]+'\\\\'):\n",
    "                    for i in im:\n",
    "                        temp_img = image.load_img(dataset_path + subfolder + '\\\\' + sF[0] + '\\\\' + i, target_size=(224,224))\n",
    "                        temp_img = image.img_to_array(temp_img)\n",
    "                        X.append(temp_img)\n",
    "                        x_true.append(temp_img)\n",
    "                        Y.append(1)\n",
    "                for _,_,im in os.walk(dataset_path+subfolder+'\\\\'+sF[1]+'\\\\'):\n",
    "                    for i in im:\n",
    "                        temp_img = image.load_img(dataset_path + subfolder + '\\\\' + sF[1] + '\\\\' + i, target_size=(224,224))\n",
    "                        temp_img = image.img_to_array(temp_img)\n",
    "                        X.append(temp_img)\n",
    "                        x_false.append(temp_img)\n",
    "                        Y.append(0)\n",
    "'''\n",
    "# Dataset2\n",
    "for _, subfolders, _  in os.walk(dataset2_path + 'Train\\\\'):\n",
    "    for subfolder in subfolders:\n",
    "        if subfolder == '1':\n",
    "            for _, _, files in os.walk(dataset2_path + 'Train\\\\' + subfolder):\n",
    "                for im in files:\n",
    "                    temp_img = image.load_img(dataset2_path + 'Train\\\\' + subfolder + '\\\\' + im,target_size=(400,400))\n",
    "                    temp_img = image.img_to_array(temp_img)\n",
    "                    X.append(temp_img / 255)\n",
    "                    x_true.append(temp_img / 255)\n",
    "#                     L.append(temp_img.shape[0])\n",
    "#                     W.append(temp_img.shape[1])\n",
    "                    Y.append(1) \n",
    "            \n",
    "        elif subfolder == '0':\n",
    "            for _, _, files in os.walk(dataset2_path + 'Train\\\\' + subfolder):\n",
    "                for im in files:\n",
    "                    temp_img = image.load_img(dataset2_path + 'Train\\\\' + subfolder + '\\\\' + im,target_size=(400,400))\n",
    "                    temp_img = image.img_to_array(temp_img)\n",
    "                    X.append(temp_img / 255)\n",
    "                    x_false.append(temp_img / 255)\n",
    "#                     L.append(temp_img.shape[0])\n",
    "#                     W.append(temp_img.shape[1])\n",
    "                    Y.append(0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "x_true = np.array(x_true)\n",
    "x_false = np.array(x_false)\n",
    "\n",
    "X /= 255\n",
    "x_true /= 255\n",
    "x_false /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400, 400, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_false.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen_true = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        horizontal_flip=False,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "datagen_false = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        horizontal_flip=False,\n",
    "        fill_mode='nearest')\n",
    "datagen_true.fit(x_true)\n",
    "datagen_false.fit(x_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug = []\n",
    "Y_aug = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in datagen_true.flow(x_true, y=None, batch_size=32):\n",
    "    i = i + 1\n",
    "    if i >= 30:\n",
    "        break\n",
    "    for img in batch:\n",
    "        X_aug.append(img)\n",
    "        Y_aug.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in datagen_true.flow(x_false, y=None, batch_size=32):\n",
    "    i = i + 1\n",
    "    if i >= 30:\n",
    "        break\n",
    "    for img in batch:\n",
    "        X_aug.append(img)\n",
    "        Y_aug.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug = np.array(X_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x228e3ff91d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File('X_augment.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"X_aug\",  data=X_aug)\n",
    "with h5py.File('Y_augment.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"Y_aug\",  data=Y_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
